{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analisi Scientifica: Impatto del Neighborhood Size sui Modelli NCA\n",
        "\n",
        "Questo notebook esegue un'analisi completa e scientifica per determinare se ha senso utilizzare un `neighborhood_size` maggiore di 3, e quali sono le differenze tra i modelli con diversi neighborhood sizes.\n",
        "\n",
        "## Obiettivi dell'Analisi:\n",
        "1. **Valutazione delle Performance**: Confronto delle metriche biologiche tra diversi neighborhood sizes\n",
        "2. **Test Statistici**: Verifica della significatività statistica delle differenze\n",
        "3. **Analisi delle Tendenze**: Identificazione di pattern e miglioramenti/peggioramenti\n",
        "4. **Complessità Computazionale**: Analisi del costo computazionale vs. benefici\n",
        "5. **Visualizzazioni Interattive**: Grafici Plotly per esplorazione approfondita\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Add parent directory to path\n",
        "# Get the directory where this notebook is located\n",
        "notebook_dir = Path().absolute()\n",
        "# Get the project root (parent of notebooks directory)\n",
        "project_root = notebook_dir.parent\n",
        "# Add to path\n",
        "sys.path.insert(0, str(project_root))\n",
        "sys.path.insert(0, str(project_root / 'experiments'))\n",
        "\n",
        "# Import the analyzer\n",
        "from experiments.analyze_neighborhood_sizes import NeighborhoodSizeAnalyzer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "print(\"Imports completati!\")\n",
        "print(f\"Project root: {project_root}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configurazione\n",
        "\n",
        "Definiamo i parametri per l'analisi:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurazione\n",
        "# Use absolute paths based on project root\n",
        "# If running from notebooks/, go up one level to project root\n",
        "if 'notebooks' in str(notebook_dir):\n",
        "    project_root = notebook_dir.parent\n",
        "else:\n",
        "    project_root = notebook_dir\n",
        "\n",
        "RESULTS_DIR = str(project_root / \"experiments\" / \"results_extended\")\n",
        "HISTORIES_PATH = str(project_root / \"histories.npy\")\n",
        "DEVICE = \"auto\"  # \"auto\", \"cuda\", \"mps\", or \"cpu\"\n",
        "N_EVALUATIONS = 10  # Numero di valutazioni per modelli stocastici\n",
        "NEIGHBORHOOD_SIZES = [3, 4, 5, 6, 7]\n",
        "FORCE_RECOMPUTE = False  # Se True, rievaluta anche se CSV esistono\n",
        "\n",
        "print(f\"Notebook directory: {notebook_dir}\")\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Results directory: {RESULTS_DIR}\")\n",
        "print(f\"Histories path: {HISTORIES_PATH}\")\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"Neighborhood sizes: {NEIGHBORHOOD_SIZES}\")\n",
        "print(f\"Number of evaluations: {N_EVALUATIONS}\")\n",
        "print(f\"Paths exist: RESULTS_DIR={os.path.exists(RESULTS_DIR)}, HISTORIES={os.path.exists(HISTORIES_PATH)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inizializzazione dell'Analyzer\n",
        "\n",
        "Creiamo l'istanza dell'analyzer e carichiamo/valutiamo i modelli:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inizializza l'analyzer\n",
        "analyzer = NeighborhoodSizeAnalyzer(\n",
        "    results_dir=RESULTS_DIR,\n",
        "    histories_path=HISTORIES_PATH,\n",
        "    device=DEVICE,\n",
        "    n_evaluations=N_EVALUATIONS\n",
        ")\n",
        "\n",
        "# Carica o valuta i modelli\n",
        "analyzer.load_or_evaluate_models(\n",
        "    neighborhood_sizes=NEIGHBORHOOD_SIZES,\n",
        "    force_recompute=FORCE_RECOMPUTE\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Modelli caricati/valutati con successo!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Esplorazione dei Dati\n",
        "\n",
        "Esaminiamo i dati delle metriche:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse delle metriche\n",
        "df = analyzer.parse_metrics()\n",
        "\n",
        "print(\"Shape del dataset:\", df.shape)\n",
        "print(\"\\nColonne:\", df.columns.tolist())\n",
        "print(\"\\nPrimi dati:\")\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistiche descrittive per modello e neighborhood size\n",
        "print(\"Statistiche descrittive per modello:\")\n",
        "print(\"=\"*60)\n",
        "for model_type in df['Model Type'].unique():\n",
        "    print(f\"\\n{model_type}:\")\n",
        "    model_data = df[df['Model Type'] == model_type]\n",
        "    print(model_data.groupby('Neighborhood Size').agg(['mean', 'std']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Statistici\n",
        "\n",
        "Eseguiamo test statistici per verificare la significatività delle differenze:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Esegui test statistici\n",
        "stat_results = analyzer.statistical_tests()\n",
        "\n",
        "# Visualizza risultati in modo più leggibile\n",
        "import json\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RISULTATI TEST STATISTICI\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for metric, model_results in stat_results.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"METRICA: {metric}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for model_type, results in model_results.items():\n",
        "        if 'kruskal_wallis' in results:\n",
        "            kw = results['kruskal_wallis']\n",
        "            significance = '***' if kw['p_value'] < 0.001 else '**' if kw['p_value'] < 0.01 else '*' if kw['p_value'] < 0.05 else '(non significativo)'\n",
        "            print(f\"\\n  {model_type}:\")\n",
        "            print(f\"    Kruskal-Wallis: H={kw['statistic']:.4f}, p={kw['p_value']:.6f} {significance}\")\n",
        "            \n",
        "            if 'pairwise' in results and results['pairwise']:\n",
        "                print(f\"    Confronti a coppie significativi:\")\n",
        "                for pair, pair_result in results['pairwise'].items():\n",
        "                    if pair_result['significant']:\n",
        "                        nb1, nb2 = pair.split('_vs_')\n",
        "                        sig = '***' if pair_result['p_value'] < 0.001 else '**' if pair_result['p_value'] < 0.01 else '*'\n",
        "                        print(f\"      NB{nb1} vs NB{nb2}: p={pair_result['p_value']:.6f} {sig}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analisi delle Tendenze\n",
        "\n",
        "Analizziamo le tendenze delle performance al variare del neighborhood size:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analisi delle tendenze\n",
        "trend_df = analyzer.performance_trend_analysis()\n",
        "\n",
        "print(\"Analisi delle Tendenze:\")\n",
        "print(\"=\"*60)\n",
        "trend_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizza miglioramenti/peggioramenti\n",
        "print(\"\\nMiglioramenti da NB=3 a NB=7:\")\n",
        "print(\"=\"*60)\n",
        "improvements = trend_df[['Model Type', 'Metric', 'Improvement_3_to_7']].copy()\n",
        "improvements = improvements.dropna()\n",
        "improvements = improvements.sort_values('Improvement_3_to_7')\n",
        "\n",
        "for _, row in improvements.iterrows():\n",
        "    improvement = row['Improvement_3_to_7']\n",
        "    direction = \"MIGLIORAMENTO\" if improvement > 0 else \"PEGGIORAMENTO\"\n",
        "    print(f\"{row['Model Type']} - {row['Metric']}: {improvement:.2f}% ({direction})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analisi della Complessità Computazionale\n",
        "\n",
        "Misuriamo il costo computazionale per ogni neighborhood size:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analisi della complessità computazionale\n",
        "complexity_df = analyzer.computational_complexity_analysis(n_samples=5)\n",
        "\n",
        "print(\"Complessità Computazionale:\")\n",
        "print(\"=\"*60)\n",
        "complexity_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizza complessità computazionale\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=complexity_df['Neighborhood Size'],\n",
        "    y=complexity_df['Mean Time (s)'],\n",
        "    mode='lines+markers',\n",
        "    name='Tempo medio (s)',\n",
        "    error_y=dict(type='data', array=complexity_df['Std Time (s)'], visible=True),\n",
        "    line=dict(width=3, color='blue'),\n",
        "    marker=dict(size=12)\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=complexity_df['Neighborhood Size'],\n",
        "    y=complexity_df['Normalized Time'],\n",
        "    mode='lines+markers',\n",
        "    name='Tempo normalizzato (vs NB=3)',\n",
        "    line=dict(width=3, color='red', dash='dash'),\n",
        "    marker=dict(size=12)\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Complessità Computazionale vs Neighborhood Size',\n",
        "    xaxis_title='Neighborhood Size',\n",
        "    yaxis_title='Tempo (s) / Fattore di Normalizzazione',\n",
        "    width=1000,\n",
        "    height=600,\n",
        "    template='plotly_white',\n",
        "    hovermode='x unified'\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizzazioni Interattive\n",
        "\n",
        "Creiamo visualizzazioni interattive con Plotly:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crea tutte le visualizzazioni\n",
        "analyzer.create_visualizations()\n",
        "\n",
        "print(\"\\n✓ Visualizzazioni create! Controlla la cartella analysis_plots/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizzazioni Personalizzate nel Notebook\n",
        "\n",
        "Creiamo visualizzazioni interattive direttamente nel notebook:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dashboard interattiva con tutte le metriche\n",
        "metric_cols = ['KL Divergence', 'Chi-Square', 'Categorical MMD', \n",
        "              'Tumor Size Diff', 'Border Size Diff', 'Spatial Variance Diff']\n",
        "\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=3,\n",
        "    subplot_titles=metric_cols,\n",
        "    vertical_spacing=0.12,\n",
        "    horizontal_spacing=0.1\n",
        ")\n",
        "\n",
        "colors = px.colors.qualitative.Set2\n",
        "df_parsed = analyzer.parse_metrics()\n",
        "\n",
        "for idx, metric in enumerate(metric_cols):\n",
        "    if metric not in df_parsed.columns:\n",
        "        continue\n",
        "    \n",
        "    row = (idx // 3) + 1\n",
        "    col = (idx % 3) + 1\n",
        "    \n",
        "    for model_idx, model_type in enumerate(df_parsed['Model Type'].unique()):\n",
        "        model_data = df_parsed[df_parsed['Model Type'] == model_type]\n",
        "        grouped = model_data.groupby('Neighborhood Size')[metric].agg(['mean', 'std'])\n",
        "        \n",
        "        sizes = grouped.index.values\n",
        "        means = grouped['mean'].values\n",
        "        stds = grouped['std'].values\n",
        "        \n",
        "        color = colors[model_idx % len(colors)]\n",
        "        \n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=sizes,\n",
        "                y=means,\n",
        "                mode='lines+markers',\n",
        "                name=model_type if idx == 0 else '',\n",
        "                line=dict(color=color, width=2),\n",
        "                marker=dict(size=8, color=color),\n",
        "                error_y=dict(type='data', array=stds, visible=True),\n",
        "                showlegend=(idx == 0),\n",
        "                hovertemplate=f'<b>{model_type}</b><br>' +\n",
        "                            'Neighborhood Size: %{x}<br>' +\n",
        "                            f'{metric}: %{{y:.4f}}<br>' +\n",
        "                            '<extra></extra>'\n",
        "            ),\n",
        "            row=row, col=col\n",
        "        )\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text=\"Dashboard Completa: Performance per Neighborhood Size\",\n",
        "    height=1000,\n",
        "    width=1800,\n",
        "    font=dict(size=10),\n",
        "    title_font_size=18,\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Box plot interattivo per una metrica specifica\n",
        "metric = 'KL Divergence'  # Cambia questa metrica per esplorare altre\n",
        "\n",
        "fig = px.box(\n",
        "    df_parsed, \n",
        "    x='Neighborhood Size', \n",
        "    y=metric, \n",
        "    color='Model Type',\n",
        "    title=f'{metric} per Neighborhood Size e Tipo di Modello',\n",
        "    labels={'Neighborhood Size': 'Neighborhood Size', metric: metric}\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    width=1200,\n",
        "    height=700,\n",
        "    font=dict(size=12),\n",
        "    title_font_size=16,\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analisi Costo-Beneficio\n",
        "\n",
        "Confrontiamo il miglioramento delle performance con il costo computazionale:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analisi costo-beneficio: miglioramento vs complessità\n",
        "# Per ogni modello, calcoliamo il miglioramento relativo e lo confrontiamo con il costo\n",
        "\n",
        "cost_benefit_analysis = []\n",
        "\n",
        "for model_type in df_parsed['Model Type'].unique():\n",
        "    model_data = df_parsed[df_parsed['Model Type'] == model_type]\n",
        "    \n",
        "    # Calcola miglioramento medio su tutte le metriche (normalizzato)\n",
        "    nb3_data = model_data[model_data['Neighborhood Size'] == 3]\n",
        "    nb7_data = model_data[model_data['Neighborhood Size'] == 7]\n",
        "    \n",
        "    if len(nb3_data) > 0 and len(nb7_data) > 0:\n",
        "        improvements = []\n",
        "        for metric in metric_cols:\n",
        "            if metric in model_data.columns:\n",
        "                mean3 = nb3_data[metric].mean()\n",
        "                mean7 = nb7_data[metric].mean()\n",
        "                if mean3 > 0:\n",
        "                    improvement = (mean3 - mean7) / mean3 * 100  # % miglioramento\n",
        "                    improvements.append(improvement)\n",
        "        \n",
        "        avg_improvement = np.mean(improvements) if improvements else 0\n",
        "        \n",
        "        # Complessità computazionale (normalizzata a NB=3)\n",
        "        complexity_nb7 = complexity_df[complexity_df['Neighborhood Size'] == 7]['Normalized Time'].values[0] if len(complexity_df[complexity_df['Neighborhood Size'] == 7]) > 0 else 1\n",
        "        \n",
        "        cost_benefit_analysis.append({\n",
        "            'Model Type': model_type,\n",
        "            'Avg Improvement (%)': avg_improvement,\n",
        "            'Computational Cost (x)': complexity_nb7,\n",
        "            'Efficiency (Improvement/Cost)': avg_improvement / complexity_nb7 if complexity_nb7 > 0 else 0\n",
        "        })\n",
        "\n",
        "cost_benefit_df = pd.DataFrame(cost_benefit_analysis)\n",
        "print(\"Analisi Costo-Beneficio (NB=3 vs NB=7):\")\n",
        "print(\"=\"*60)\n",
        "cost_benefit_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizza analisi costo-beneficio\n",
        "fig = go.Figure()\n",
        "\n",
        "for _, row in cost_benefit_df.iterrows():\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=[row['Computational Cost (x)']],\n",
        "        y=[row['Avg Improvement (%)']],\n",
        "        mode='markers+text',\n",
        "        name=row['Model Type'],\n",
        "        marker=dict(size=15),\n",
        "        text=[row['Model Type']],\n",
        "        textposition=\"top center\",\n",
        "        hovertemplate=f\"<b>{row['Model Type']}</b><br>\" +\n",
        "                      f\"Miglioramento: {row['Avg Improvement (%)']:.2f}%<br>\" +\n",
        "                      f\"Costo: {row['Computational Cost (x)']:.2f}x<br>\" +\n",
        "                      f\"Efficienza: {row['Efficiency (Improvement/Cost)']:.2f}<br>\" +\n",
        "                      \"<extra></extra>\"\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Analisi Costo-Beneficio: Miglioramento vs Complessità Computazionale',\n",
        "    xaxis_title='Costo Computazionale (normalizzato a NB=3)',\n",
        "    yaxis_title='Miglioramento Medio delle Performance (%)',\n",
        "    width=1000,\n",
        "    height=700,\n",
        "    template='plotly_white',\n",
        "    hovermode='closest'\n",
        ")\n",
        "\n",
        "# Aggiungi linee di riferimento\n",
        "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Nessun miglioramento\")\n",
        "fig.add_vline(x=1, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Costo base (NB=3)\")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generazione Report Completo\n",
        "\n",
        "Generiamo il report testuale completo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Genera report completo\n",
        "analyzer.generate_report()\n",
        "\n",
        "print(\"\\n✓ Report generato! Controlla il file neighborhood_size_analysis_report.txt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusioni e Raccomandazioni\n",
        "\n",
        "Sintesi dei risultati principali:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trova la configurazione migliore per ogni metrica\n",
        "print(\"=\"*60)\n",
        "print(\"CONFIGURAZIONI MIGLIORI PER METRICA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for metric in metric_cols:\n",
        "    if metric not in df_parsed.columns:\n",
        "        continue\n",
        "    \n",
        "    best_idx = df_parsed[metric].idxmin()\n",
        "    best_row = df_parsed.loc[best_idx]\n",
        "    print(f\"\\n{metric}:\")\n",
        "    print(f\"  Migliore: {best_row['Model Type']} con NB={best_row['Neighborhood Size']}\")\n",
        "    print(f\"  Valore: {best_row[metric]:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RACCOMANDAZIONI\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "1. Analizza i test statistici per determinare se le differenze sono significative\n",
        "2. Considera il trade-off tra miglioramento delle performance e costo computazionale\n",
        "3. Verifica se neighborhood sizes maggiori forniscono miglioramenti consistenti\n",
        "4. Valuta se il miglioramento giustifica l'aumento del costo computazionale\n",
        "5. Considera l'uso di neighborhood size maggiore solo se:\n",
        "   - I test statistici mostrano differenze significative\n",
        "   - Il miglioramento è consistente su tutte le metriche\n",
        "   - Il costo computazionale è accettabile per il tuo caso d'uso\n",
        "\"\"\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
